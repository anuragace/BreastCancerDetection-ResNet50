{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51bf174b-d648-4c4f-9f0b-7de61aa63741",
      "metadata": {
        "id": "51bf174b-d648-4c4f-9f0b-7de61aa63741",
        "outputId": "9a4d66b5-fcf2-4f40-af11-08c723824af8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in o:\\sem3\\env\\lib\\site-packages (2.1.1+cu121)\n",
            "Requirement already satisfied: torchvision in o:\\sem3\\env\\lib\\site-packages (0.16.1+cu121)\n",
            "Requirement already satisfied: filelock in o:\\sem3\\env\\lib\\site-packages (from torch) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in o:\\sem3\\env\\lib\\site-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in o:\\sem3\\env\\lib\\site-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in o:\\sem3\\env\\lib\\site-packages (from torch) (3.2)\n",
            "Requirement already satisfied: jinja2 in o:\\sem3\\env\\lib\\site-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: fsspec in o:\\sem3\\env\\lib\\site-packages (from torch) (2023.9.2)\n",
            "Requirement already satisfied: numpy in o:\\sem3\\env\\lib\\site-packages (from torchvision) (1.24.3)\n",
            "Requirement already satisfied: requests in o:\\sem3\\env\\lib\\site-packages (from torchvision) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in o:\\sem3\\env\\lib\\site-packages (from torchvision) (10.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in o:\\sem3\\env\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in o:\\sem3\\env\\lib\\site-packages (from requests->torchvision) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in o:\\sem3\\env\\lib\\site-packages (from requests->torchvision) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in o:\\sem3\\env\\lib\\site-packages (from requests->torchvision) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in o:\\sem3\\env\\lib\\site-packages (from requests->torchvision) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in o:\\sem3\\env\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install torch torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "8666d905-0ce8-467e-89e0-c3323e626867",
      "metadata": {
        "id": "8666d905-0ce8-467e-89e0-c3323e626867"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import datasets, models\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import copy\n",
        "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "f09b9675-52b0-45ce-b59a-e26bd3b9f833",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f09b9675-52b0-45ce-b59a-e26bd3b9f833",
        "outputId": "66792895-8d95-41f7-a1e5-aedbb51bf896"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch Version: 2.2.1+cu121\n",
            "CUDA Available: False\n",
            "CUDA Version: 12.1\n"
          ]
        }
      ],
      "source": [
        "print(\"PyTorch Version:\", torch.__version__)\n",
        "print(\"CUDA Available:\", torch.cuda.is_available())\n",
        "print(\"CUDA Version:\", torch.version.cuda)\n",
        "if torch.cuda.is_available():\n",
        "    print(\"CUDA Device Name:\", torch.cuda.get_device_name(0))\n",
        "    print(\"Current CUDA Device ID:\", torch.cuda.current_device())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tgYd9rDmWrYl",
        "outputId": "0a8e35a1-ae8e-4a09-e2d4-cc7c85875ee0"
      },
      "id": "tgYd9rDmWrYl",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from zipfile import ZipFile\n",
        "\n",
        "# # Specify the zip file path\n",
        "# zip_ref = ZipFile(\"/content/drive/MyDrive/CHM/breast.zip\", 'r')\n",
        "\n",
        "# # Extract all files to the current directory (you can specify a different path)\n",
        "# zip_ref.extractall()\n",
        "\n",
        "# zip_ref.close()"
      ],
      "metadata": {
        "id": "N5u4gt-zW5ax"
      },
      "id": "N5u4gt-zW5ax",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# from torchvision import transforms, datasets\n",
        "# from torch.utils.data import DataLoader, SubsetRandomSampler\n",
        "# import numpy as np\n",
        "# import torch\n",
        "\n",
        "# # Set the directory for the data\n",
        "# data_dir = '/content/breast/classes/'\n",
        "\n",
        "# # Define transformations\n",
        "# transformations = transforms.Compose([\n",
        "#     transforms.Resize((224, 224)),\n",
        "#     transforms.RandomHorizontalFlip(),\n",
        "#     transforms.ToTensor(),\n",
        "#     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "# ])\n",
        "\n",
        "# # Initialize the dataset using ImageFolder\n",
        "# dataset = datasets.ImageFolder(root=data_dir, transform=transformations)\n",
        "\n",
        "# # Print out class names to verify\n",
        "# print(\"Classes:\", dataset.classes)\n",
        "\n",
        "# # Splitting data indices for training, validation, and testing\n",
        "# np.random.seed(42)\n",
        "# indices = np.random.permutation(len(dataset))\n",
        "# split_train = int(0.7 * len(indices))\n",
        "# split_val = int(0.85 * len(indices))\n",
        "# train_indices, val_indices, test_indices = indices[:split_train], indices[split_train:split_val], indices[split_val:]\n",
        "\n",
        "# # Creating samplers for each set\n",
        "# train_sampler = SubsetRandomSampler(train_indices)\n",
        "# val_sampler = SubsetRandomSampler(val_indices)\n",
        "# test_sampler = SubsetRandomSampler(test_indices)\n",
        "\n",
        "# # Creating DataLoader for each set\n",
        "# train_loader = DataLoader(dataset, batch_size=16, sampler=train_sampler)\n",
        "# val_loader = DataLoader(dataset, batch_size=16, sampler=val_sampler)\n",
        "# test_loader = DataLoader(dataset, batch_size=16, sampler=test_sampler)\n",
        "\n",
        "# # Print out the number of samples in each set\n",
        "# print(\"Number of training samples:\", len(train_indices))\n",
        "# print(\"Number of validation samples:\", len(val_indices))\n",
        "# print(\"Number of test samples:\", len(test_indices))"
      ],
      "metadata": {
        "id": "Qg2iklyVW9Wc"
      },
      "id": "Qg2iklyVW9Wc",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# import torch\n",
        "# import numpy as np\n",
        "# import pandas as pd\n",
        "# from torchvision import datasets, transforms\n",
        "# from torch.utils.data import DataLoader, SubsetRandomSampler, Subset\n",
        "# from sklearn.model_selection import StratifiedShuffleSplit\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# # Metadata loading and preprocessing\n",
        "# metadata_path = '/content/breast/metadata.csv'\n",
        "# metadata = pd.read_csv(metadata_path)\n",
        "\n",
        "# # Calculate class weights based on TumorType in metadata\n",
        "# def estimate_weights_mfb(label):\n",
        "#     class_counts = metadata['TumorType'].value_counts()\n",
        "#     class_weights = class_counts.median() / class_counts.reindex(label, fill_value=0)\n",
        "#     return class_weights.values\n",
        "\n",
        "# label = ['DC', 'F', 'MC', 'LC', 'TA', 'PC', 'PT', 'A']  # Classes as per metadata TumorType\n",
        "# class_weights = torch.FloatTensor(estimate_weights_mfb(label))\n",
        "# print(\"Class weights:\", class_weights)\n",
        "\n",
        "# # Define transformations\n",
        "# transform_train = transforms.Compose([\n",
        "#     transforms.Resize((224, 224)),\n",
        "#     transforms.RandomHorizontalFlip(),\n",
        "#     transforms.RandomRotation(degrees=60),\n",
        "#     transforms.ToTensor(),\n",
        "#     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "# ])\n",
        "\n",
        "# transform_test = transforms.Compose([\n",
        "#     transforms.Resize((224, 224)),\n",
        "#     transforms.ToTensor(),\n",
        "#     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "# ])\n",
        "\n",
        "# # Initialize dataset\n",
        "# data_dir = '/content/breast/classes/'\n",
        "# dataset = datasets.ImageFolder(root=data_dir, transform=transform_train)\n",
        "\n",
        "# data_labels = []\n",
        "# unmatched_entries = []\n",
        "# for img_path, _ in dataset.imgs:\n",
        "#     # Split the path and extract the SlideID\n",
        "#     filename = img_path.split('/')[-1]  # Gets 'SOB_B_A-14-22549AB-100-001.png'\n",
        "#     slide_id = filename.split('-')[2]  # Split by '-' and get the fourth segment\n",
        "\n",
        "#     # Find the matching entry in the metadata\n",
        "#     metadata_entry = metadata[metadata['SlideID'] == slide_id]\n",
        "\n",
        "#     if not metadata_entry.empty:\n",
        "#         tumor_type = metadata_entry['TumorType'].values[0]\n",
        "#         data_labels.append(tumor_type)\n",
        "#     else:\n",
        "#         unmatched_entries.append(slide_id)\n",
        "\n",
        "# # Print the results of the matching process\n",
        "# if unmatched_entries:\n",
        "#     print(f\"Warning: No metadata entries matched for {len(unmatched_entries)} images.\")\n",
        "#     print(\"Unmatched SlideIDs:\", unmatched_entries)\n",
        "# else:\n",
        "#     print(\"All images matched successfully.\")\n",
        "\n",
        "# # Create Stratified Splits\n",
        "# splitter = StratifiedShuffleSplit(n_splits=1, test_size=0.36)\n",
        "# for train_idx, temp_idx in splitter.split(dataset.imgs, data_labels):\n",
        "#     pass  # temp_idx to be further split into validation and test\n",
        "\n",
        "# # Split temp into validation and test\n",
        "# temp_labels = [data_labels[i] for i in temp_idx]\n",
        "# temp_splitter = StratifiedShuffleSplit(n_splits=1, test_size=0.44)  # 0.44 of 0.36 is 0.16 (test size)\n",
        "# for val_idx, test_idx in temp_splitter.split(np.zeros(len(temp_labels)), temp_labels):\n",
        "#     pass\n",
        "\n",
        "# # Loaders\n",
        "# batch_size = 10\n",
        "# train_sampler = SubsetRandomSampler(train_idx)\n",
        "# val_sampler = SubsetRandomSampler(val_idx)\n",
        "# test_sampler = SubsetRandomSampler(test_idx)\n",
        "\n",
        "# train_loader = DataLoader(dataset, batch_size=batch_size, sampler=train_sampler)\n",
        "# val_loader = DataLoader(dataset, batch_size=batch_size, sampler=val_sampler)\n",
        "# test_loader = DataLoader(dataset, batch_size=batch_size, sampler=test_sampler)\n",
        "\n",
        "# # Output sizes\n",
        "# print(f\"Train set size: {len(train_idx)}\")\n",
        "# print(f\"Validation set size: {len(val_idx)}\")\n",
        "# print(f\"Test set size: {len(test_idx)}\")\n",
        "\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# # Count occurrences of each label\n",
        "# label_counts = pd.Series(data_labels).value_counts().sort_index()\n",
        "\n",
        "# # Plotting\n",
        "# plt.figure(figsize=(10, 6))\n",
        "# label_counts.plot(kind='bar')\n",
        "# plt.xlabel('Tumor Type')\n",
        "# plt.ylabel('Frequency')\n",
        "# plt.title('Distribution of Tumor Types in Dataset')\n",
        "# plt.xticks(rotation=45)\n",
        "# plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 662
        },
        "id": "QuAiXgiSsOG0",
        "outputId": "dd3ceea8-f8e0-49cb-828e-797cbb6095a9"
      },
      "id": "QuAiXgiSsOG0",
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class weights: tensor([0.1772, 0.6154, 0.7207, 0.9412, 1.0667, 1.1268, 1.3223, 1.4159])\n",
            "All images matched successfully.\n",
            "Train set size: 1331\n",
            "Validation set size: 420\n",
            "Test set size: 330\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "from torchvision import transforms, datasets\n",
        "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
        "from torch import nn\n",
        "\n",
        "# Set the directory for the data\n",
        "data_dir = '/content/breast/classes/'\n",
        "\n",
        "# Define transformations with additional data augmentation\n",
        "transformations = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(20),  # Rotates the image by up to 20 degrees\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2),  # Optional: adjust brightness and contrast\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Initialize the dataset using ImageFolder\n",
        "dataset = datasets.ImageFolder(root=data_dir, transform=transformations)\n",
        "\n",
        "# Print out class names to verify\n",
        "print(\"Classes:\", dataset.classes)\n",
        "\n",
        "# Prepare class weights for handling class imbalance\n",
        "class_weights = torch.tensor([0.1778, 0.6154, 0.7273, 0.9412, 1.0667, 1.1429, 1.3333, 1.4545], dtype=torch.float)\n",
        "class_weights = class_weights / class_weights.sum()  # Normalize weights to sum to 1\n",
        "weighted_sampler = torch.utils.data.WeightedRandomSampler(weights=class_weights, num_samples=len(dataset), replacement=True)\n",
        "\n",
        "# Splitting data indices for training, validation, and testing\n",
        "np.random.seed(42)\n",
        "indices = np.random.permutation(len(dataset))\n",
        "split_train = int(0.7 * len(indices))\n",
        "split_val = int(0.85 * len(indices))\n",
        "train_indices, val_indices, test_indices = indices[:split_train], indices[split_train:split_val], indices[split_val:]\n",
        "\n",
        "# Creating samplers for each set using weights\n",
        "train_sampler = SubsetRandomSampler(train_indices)\n",
        "val_sampler = SubsetRandomSampler(val_indices)\n",
        "test_sampler = SubsetRandomSampler(test_indices)\n",
        "\n",
        "# Creating DataLoader for each set\n",
        "train_loader = DataLoader(dataset, batch_size=16, sampler=train_sampler)\n",
        "val_loader = DataLoader(dataset, batch_size=16, sampler=val_sampler)\n",
        "test_loader = DataLoader(dataset, batch_size=16, sampler=test_sampler)\n",
        "\n",
        "# Print out the number of samples in each set\n",
        "print(\"Number of training samples:\", len(train_indices))\n",
        "print(\"Number of validation samples:\", len(val_indices))\n",
        "print(\"Number of test samples:\", len(test_indices))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7E6r5Ys7xey",
        "outputId": "96876f0b-0b3e-4516-f8fb-df4efd162da9"
      },
      "id": "A7E6r5Ys7xey",
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes: ['Adenosis', 'Ductal_Carcinoma', 'Fibroadenoma', 'Lobular_Carcinoma', 'Mucinous_Carcinoma', 'Papillary_Carcinoma', 'Phyllodes_Tumor', 'Tubular_Adenoma']\n",
            "Number of training samples: 1456\n",
            "Number of validation samples: 312\n",
            "Number of test samples: 313\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "# Assuming train_idx, val_idx, test_idx are the indices for training, validation, and test sets respectively\n",
        "train_labels = [data_labels[i] for i in train_idx]\n",
        "val_labels = [data_labels[i] for i in val_idx]\n",
        "test_labels = [data_labels[i] for i in test_idx]\n",
        "\n",
        "# Count the occurrences of each class in each subset\n",
        "train_counter = Counter(train_labels)\n",
        "val_counter = Counter(val_labels)\n",
        "test_counter = Counter(test_labels)\n",
        "\n",
        "print(\"Training set class distribution:\", train_counter)\n",
        "print(\"Validation set class distribution:\", val_counter)\n",
        "print(\"Test set class distribution:\", test_counter)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWRwMTpQzPLT",
        "outputId": "adb92777-6ee2-40d9-c5d3-8267cc35a483"
      },
      "id": "FWRwMTpQzPLT",
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set class distribution: Counter({'DC': 599, 'F': 166, 'MC': 142, 'TA': 96, 'PC': 91, 'LC': 88, 'PT': 77, 'A': 72})\n",
            "Validation set class distribution: Counter({'DC': 359, 'A': 61})\n",
            "Test set class distribution: Counter({'DC': 278, 'A': 52})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "72ded023-8db9-4952-9977-73f9af3affb5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72ded023-8db9-4952-9977-73f9af3affb5",
        "outputId": "06dd7fc9-da5c-41cd-d8c0-7ca4fbae2f94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model on CUDA: False\n"
          ]
        }
      ],
      "source": [
        "# Load a pretrained ResNet-50 model\n",
        "model = models.resnet50(pretrained=True)\n",
        "\n",
        "# Modify the classifier layer to match the number of classes in your dataset\n",
        "num_features = model.fc.in_features\n",
        "num_classes = len(dataset.classes)\n",
        "model.fc = torch.nn.Linear(num_features, num_classes)\n",
        "\n",
        "# Move the model to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "# Confirm model is on GPU\n",
        "print(\"Model on CUDA:\", next(model.parameters()).is_cuda)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "a83d1b1e-ba04-4803-9d17-725bf15336f2",
      "metadata": {
        "id": "a83d1b1e-ba04-4803-9d17-725bf15336f2"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "from torch import nn\n",
        "\n",
        "# Define class weights for handling class imbalance\n",
        "class_weights = torch.tensor([0.1778, 0.6154, 0.7273, 0.9412, 1.0667, 1.1429, 1.3333, 1.4545], dtype=torch.float)\n",
        "if torch.cuda.is_available():\n",
        "    class_weights = class_weights.cuda()  # Move to GPU if CUDA is available\n",
        "\n",
        "# Loss function with class weights\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
        "\n",
        "# Optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "4e8e6f6c-bbd5-4504-9306-3367ada4c470",
      "metadata": {
        "id": "4e8e6f6c-bbd5-4504-9306-3367ada4c470"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "def train_model(model, criterion, optimizer, train_loader, val_loader, num_epochs=25, device='cuda'):\n",
        "    model.to(device)\n",
        "    best_acc = 0.0\n",
        "    for epoch in range(num_epochs):\n",
        "        start_time = time.time()  # Start time of the epoch\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "                loader = train_loader\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "                loader = val_loader\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in loader:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # Zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # Forward\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # Backward and optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # Statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / len(loader.sampler)\n",
        "            epoch_acc = running_corrects.double() / len(loader.sampler)\n",
        "\n",
        "            print(f'{phase.capitalize()} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "\n",
        "            # Deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        end_time = time.time()  # End time of the epoch\n",
        "        print(f'Epoch duration: {end_time - start_time:.2f} seconds')\n",
        "        print()\n",
        "\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # Load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68274794-6397-4af7-ac4b-abcf51d4f2c3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68274794-6397-4af7-ac4b-abcf51d4f2c3",
        "outputId": "2bf4d88b-0534-4e69-c400-6790b9c6ac5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "----------\n"
          ]
        }
      ],
      "source": [
        "trained_model = train_model(model, criterion, optimizer, train_loader, val_loader, num_epochs=100, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4711d553-41f6-4f2d-8bcf-55eac9bfa727",
      "metadata": {
        "id": "4711d553-41f6-4f2d-8bcf-55eac9bfa727"
      },
      "outputs": [],
      "source": [
        "# Save the entire model\n",
        "torch.save(model, 'O:/Sem3/CHM/Breast_Cancer_Classification/breast/breast/resnet50_breakhis_complete_model.pth')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7600ac33-2c63-4c6e-9a36-57fe94393068",
      "metadata": {
        "id": "7600ac33-2c63-4c6e-9a36-57fe94393068"
      },
      "outputs": [],
      "source": [
        "# Load the entire model\n",
        "complete_model_path = 'O:/Sem3/CHM/Breast_Cancer_Classification/breast/breast/resnet50_breakhis_complete_model.pth'\n",
        "model = torch.load(complete_model_path)\n",
        "model.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.eval()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "03444376-18d2-4645-9dc4-a0b02bef3f90",
      "metadata": {
        "id": "03444376-18d2-4645-9dc4-a0b02bef3f90"
      },
      "source": [
        "### Evaluation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e40f28e5-d597-43db-90df-a9dc1b28d8aa",
      "metadata": {
        "id": "e40f28e5-d597-43db-90df-a9dc1b28d8aa"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import torch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed8345b4-e5b4-41fc-bc43-9f2eb8a0f474",
      "metadata": {
        "id": "ed8345b4-e5b4-41fc-bc43-9f2eb8a0f474"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, test_loader, device):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    true_labels = []\n",
        "    pred_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            true_labels.extend(labels.cpu().numpy())\n",
        "            pred_labels.extend(preds.cpu().numpy())\n",
        "\n",
        "    accuracy = np.sum(np.array(true_labels) == np.array(pred_labels)) / len(true_labels)\n",
        "    print(f'Accuracy: {accuracy:.4f}')\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_report(true_labels, pred_labels, target_names=test_loader.dataset.classes))\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(confusion_matrix(true_labels, pred_labels))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14cc75c8-5026-4669-b920-ae9ed6aa71a8",
      "metadata": {
        "id": "14cc75c8-5026-4669-b920-ae9ed6aa71a8",
        "outputId": "3d136b01-bc42-41f7-c38a-f04a4cb028c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9553\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      benign       0.96      0.89      0.92       345\n",
            "   malignant       0.96      0.98      0.97       842\n",
            "\n",
            "    accuracy                           0.96      1187\n",
            "   macro avg       0.96      0.94      0.94      1187\n",
            "weighted avg       0.96      0.96      0.95      1187\n",
            "\n",
            "Confusion Matrix:\n",
            "[[306  39]\n",
            " [ 14 828]]\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the trained model\n",
        "evaluate_model(trained_model, test_loader, device)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}